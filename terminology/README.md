# terminology

---

## List
|n|name|desc.|O/P|
|-|----|-----|---|
|1|stuctured data||<img src="https://i.imgur.com/A1lvXzq.png">|
|2|semi-structured data|commonly encountered in varuous domains :<br/><br/>* social media feeds<br/>* sensor data from IoT device<br/>* log files<br/><br/>businesses can capture & store diverse data sources that may have evolving schemas or complex relations<br/><br/>you can use as NoSQL databases<br/><br/>These databases, such as<br/><br/>* Azure Cosmos DB<br/><br/>making them suitable for handling diverse data formats & evolving schemas|<img src="https://i.imgur.com/ZcIuxpR.png">|
|3|unstructured data|It includes data in its rawest form, such as:<br/><br/>* text documents<br/>&ensp;* emails<br/>&ensp;* news articles<br/>&ensp;* social media posts<br/>&ensp;* images:<br/>&ensp;&ensp;* photographs<br/>&ensp;&ensp;* scanned documents<br/>&ensp;&ensp;* audio recordings<br/>&ensp;&ensp;* videos<br/>* images<br/>* audio files<br/>* videos<br/>* & more<br/><br/>Managing & deriving value from unstructured data requires specialized tools & techniques. Technologies such as :<br/><br/>* natural language processing (NLP)<br/>* image recognition<br/>* **audio transcription play** a significant role in analyzing & extracting meaningfull information from unstructured data sources<br/><br/>However, its sheer volume & lack of predefined structure pose significant challenges in terms of **storage**, **processing**, & **analysis**|<img src="https://i.imgur.com/aBy7YNH.png">|
|4|delimited file formats|comma-separated values(CSV)<br/><br/>comma (or **delimiter**) acts as a marker to distinguish one field fro the other|<img src="https://i.imgur.com/Rue2Nts.png">|
|5|file format|json<br/>xml<br/>parquet<br/><br/><ins>Parquet file format</ins><br/>Parquet is a collumnar storage file format designed for efficient data **processing** & **analytics** in **big data* environment. It provides a highly optimized & compressed representation fo structured data, making it well-suited for handling large dataset.<br/><br/>Parquet is widely adopted in big data processing frameworks such as **Apache Hadoop** & **Apache Spark**<br/><br/><ins>advantages</ins>:<br/>storage format reduces disk I/O & improves query performance, especially when queries involve only a subset of columns.<br/> * advanced compression techniques, such as run-lenght encoding (RLE) & dictionary encoding|xml file format:<br/><img src="https://i.imgur.com/je0dI0r.png"><br/><br/>parquet file format:<br/><img src="https://i.imgur.com/bUKFNws.png">|
|6|SQL dialects|<ins>MariaDB</ins><br/>MariaDB (open-source) is a fork of MySQL created by the original developers of MySQL, and itâ€™s intended to remain open-source. MariaDB is designed to be highly compatible with MySQL, meaning that, in most cases, data and code can be switched seamlessly between the two. MariaDB includes more storage engines than MySQL, and it includes several features not found in MySQL.<br/><br/><ins>PL/SQL</ins><br/>Procedural Language/SQL, a dialect developed by Oracle<br/><br/><ins>Transact-SQL(T-SQL)</ins><br/>This is Microsoft's proprietary extension of SQL, which includes a set of programmable functions & procedural programming. T-SQL is primarily used with Microsoft SQL Server<br/><br/><ins>MySQL</ins><br/>MySQL (open-source) uses a dialect of SQL that is rich in function, including string processing, date & time processing, & advanced features such as replication & partitioning<br/><br/><ins>PostgreSQL</ins><br/>PostgreSQL (open-source), supports a version of SQL that includes many features not available in other database systems, such as window functions & common table expressions|
|7|Azure Synapse Analytics|Formerly SQL Data **Warehouse**, Azure Synapse Analytics is an analytics service that brings together big data and data warehousing. It gives you the freedom to query data on your terms, using serverless on-demand or provisioned resources.|
|8|Azure SQL Server|IaaS|
|9|Azure SQL Managed Instance|PaaS|<img src="https://i.imgur.com/Dw63q1Q.png"><br/>what is sql managed instance:<br/><img src="https://i.imgur.com/mpHp82h.png">|
|10|Azure SQL Edge|zure SQL Edge is an optimized relational database engine geared toward Internet of Things (**IoT**) and edge computing scenarios. It offers a small footprint that can run a variety of devices from low-power edge devices to high-performance edge servers|<img src="https://i.imgur.com/MX0T3wY.png">|
|11|Azure SQL Database|PaaS|
|12|Azure Database for MySQL||
|13|NoSQL|NoSQL in Azure refers to a category of database management systems that do not use a traditional relational database model. Instead of relying on fixed schema tables and rows, NoSQL databases use flexible schemas, allowing them to handle large volumes of diverse data types such as structured, semi-structured, and unstructured data. These databases are designed for scalability, high performance, and to support large-scale, distributed applications.<br/><br/><ins>Azure Cosmos DB</ins><br/>A fully managed, globally distributed NoSQL database service that supports multiple data models, including document, key-value, graph, and column-family. Cosmos DB offers multi-master replication, guara<br/><br/><ins>Azure Table Storage</ins><br/>A NoSQL key-value store that provides a simple and cost-effective solution for storing large amounts of structured, non-relational data. It is often used for applications that require scalable storage, like web applications, configuration settings, or user session data.<br/><br/><ins>Azure Cache for Redis</ins><br/>Although primarily a caching solution, Redis on Azure can also serve as a NoSQL key-value store. It supports a variety of data structures such as strings, hashes, lists, sets, and more, offering in-memory storage for high-speed access|
|14|azure data lake storage gen2|
|15|storage account||options:<br/><img src="https://i.imgur.com/bp1A4bv.png"><br/>flowchart of the security features:<br/><img src="https://i.imgur.com/6cZFcpx.png"><br/>Scalability potential of azure storage account:<br/><img src="https://i.imgur.com/ZrJ5eKq.png">|
|16|POSIX-compliant ACLs|
|17|Azure Databricks|
|18|Azure Data Factory|
|19|Azure File Sync|
|20|Cassandra API|
|21|Gremlin API|
|22|Azure HDInsight|
|23|MongoDB API|
|24|Table API|
|25|Turnkey Global Distribution|
|26|Power BI||Data journey from Azure data sources to visualization to Power BI:<br/><img src="https://i.imgur.com/gUPpfVh.png">Power BI Web:<br/><img src="https://i0.wp.com/radacad.com/wp-content/uploads/2015/08/35.png"><br/>Power BI Desktop vs Power BI Service<br/><img src="https://i.imgur.com/wmtGjKu.png">|
|27|Azure Analysis Services|
|28|data types||<img src="https://i.imgur.com/PkCsvSR.png">|
|29|ETL||<img src="https://i.imgur.com/lB45r9y.png">|
|30|ELT|the **data** will be copied in its **raw format** to the **data lake**, & then modeling **routine** are performed so that this data is prepared for **consumption**|<img src="https://i.imgur.com/lRKSOpl.png">|
|31|Data Pipeline|
|32|Microsoft Fabric|SaaS|
|33|Batch data|Data ingestion is the process of **copying operational data** from data sources to organize it in an **analytical database**.<br/><br/>When batching the data, the operation is offline|Batch processing vs Streaming processing:<br/><img src="https://raw.githubusercontent.com/pc-aide/dp-900/main/terminology/batch%20prcessing%20vs%20stream%20processing.png">|
|34|Streaming data|
|35|Azure Data Explorer (ADX) Cluster|
|36|Spark Structured Streaming|
|37|Start Schema||<img src="https://i.imgur.com/bPK2fK9.png">|
|38|Snowflake schema||<img src="https://i.imgur.com/PTQzCKn.png">|
|39|transactional solutions|Transactional database are used by system for basic opeations :<br/>* creating<br/>* reading<br/>* updating<br/>* deleting<br/><br/>A transactional database is commonly known as online transaction processing (**OLTP**) considering that this type of database serves online transactional operations between the application & the database|<img src="https://i.imgur.com/wmbqvrV.png">|
|40|analytical solutions|Analytical databases use a process called online analytical processing (**OLAP**) & have undergone a grat evolution in recent year with the emergence of data warehouse & big data platforms<br/><br/>Analytical databases are constittuted through a process of data **ingestion**, & they are responsible for **processing** & **transforming** the data into insights & information & then making this processed information available for **consumption**.|<img src="https://i.imgur.com/tWE4z4s.png">|
|41|Roles and responsibilities for data workloads|<ins>Database administrator (DBA)</ins><br/><br/><ins>Data engineer</ins><br/>It's a multidisciplinary role, so it needs knowledge of programming(commonly Python, R, Scala), data transformation, and mathematics, among other areas<br/><br/><ins>Data analyst</ins>|
|42|OLTP vs OLAP|The preceding figure demonstrates the traditional flow of data, which is sourced & stored in transactional OLTP databases & then moved to OLAP analytical databases for **data intelligence generation**.|<img src="https://i.imgur.com/lqMNPWW.png">|
|43|key-value database|no predefined schema, tables, or columns, & no relationships between the entities|<img src="https://i.imgur.com/k1x6Wnt.png"><br/>key-value database example<br/><img src="https://i.imgur.com/U0s7Lra.png">|
|44|graph database|A graph database contains **nodes**(object information) & **edges**(object relationship information)|<img src="https://i.imgur.com/Lj1rvyt.png"><br/><img src="https://i.imgur.com/mtVd8jR.png">|
|45|unstructured data|such as **audio,videos,image, or binary records** without a defined organization<br/><br/>it's common, for example, for unstructured data such as **audio** to be **transcribed** using **artificial intelligence**, generating a mass of semi-structured data for processing|
|46|relational database|however, after setting up this table, you realize tha you have **clients** that have more **than one address** & zip code, & even more one mobile phone number. how can you solve this issues?<br/><br/>To face problems like this one, we can use **normalization** one more time. Normalization is done when there is a need to **split a table**(CUSTOMER, in this example) into more child tables that are correlated to the initial table<br/><br/><ins>Relational data</ins><br/>A table is a materialized structure of an **entity** for storing structured data in **columns** & **row**|<img src="https://i.imgur.com/OLhFKhm.png"><br/>we change the CUSTOMER table as :<br/>|
|47|Azure SQL Database elastic pools|
|48|ACID properties|<ins>Atomicity</ins><br/>This is the property that controls the transaction & defines whether it was successfully performed completely to commit or must be canceled by performing a rollback. Database technology should ensure atomicty<br/><br/><ins>Consistency</ins><br/>For a running transaction, it is important to evaluate consistency between the database state before receiving the data & the database state after receiving the data. For example, in a back transfer, when funds are added to an account, those funds must have a source.Therefore, it's important to know this source & whether the fund's source exit process has already been performed before confirming the inclusion in this new account<br/><br/><ins>Isolation</ins><br/>This property evaluates whether there are multiple executions of transactions similar to the current one and if so, it keeps the database in the same state. It then evaluates whether the execution of transactions was sequential. In the bank transfer example, if multiple transactions are sent simultaneously, it checks whether the amounts have already left the source for all transactions, or you need to review one by one, transaction per transaction.<br/><br/><ins>Durability</ins><br/>This is responsible for evaluating whether a transaction remains in the committed database even if there is a failure during the process, such as a power outage or latency at the time of recording the record.|
|49|Azure Data studio||<img src="https://i.imgur.com/k8dvC4C.png">|
|50|SQL Server Management Studio|
|51|Azure Synapse Analytics Studio||<img src="https://i.imgur.com/RGBG70M.png">|
|52|data masks|help standardize your data in columns<br/>eg : email:<br/>text+@+an extension|
|53|Database schema|Database schema is a **table** and **column model** that is **designed** and **implemented** before we start using a relational database|
|54|Data normalization|to troubleshoot **data duplication**, a process called normalization|A sales table example:<br/><img src="https://i.imgur.com/8tHBQRs.png"><br/><br/>An example of a relational database (relation many tables) with normalization applied:<br/><img src="https://i.imgur.com/ZF2wETO.png">|
|55|Fact vs Dimension Table||Fact Table (eg : Sales Tables)<br/><img src="https://i.imgur.com/yrdQC3l.png"><br/><br/>Dimensions Table (attributes)<br/><img src="https://i.imgur.com/vbs6aSN.png"><br/><img src="https://i.imgur.com/SVV20Gh.png"><br/><img src="https://i.imgur.com/1Z7wZVF.png">|
|56|database components|<ins>Views</ins><br/><br/><ins>stored procedures</ins><br/><br/><ins>triggers</ins><br/><br/><ins>indexes</ins>|
|57|document database||<img src="https://i.imgur.com/SYQdVFs.png">|
|58|column family database|<ins>Cassandra</ins><br/><br/><ins>HBase</ins>|<img src="https://i.imgur.com/hKOQJvx.png">|
|59|microservices|Modern software architecture (microservices)|
|60|data pipeline|for example, use **Azure SQL Database** to run a store procedure that searches for data values, & then run a processing **routine** with Azure **Databricks** by applying a custom data model. All of these are steps in a data pipeline|
|61|Data flow in an analytical env||<img src="https://i.imgur.com/9rbPD9D.png">|
|62|data analysts|Often, these models are called **data cubes** because they demonstate a particular subject (called a **fact**) in various perspectives (called **dimensions**), thus allowing data analysts to consume this data & drill down to understand the details of the information.<br/><br/>Models are defined by the quantitative values that you want to analyze or report (known as **measures**) & the entities by which you want to aggregate them & are based on connec data tables (known as **dimensions**)<br/><br/>The model is conceptually a **multidimensional** structure known as a **cube**, where each location in which the dimensions meet represents an added value<br/><br/><ins>Dimension tables</ins>|<img src="https://i.imgur.com/Ob8NigF.png"><br/>In the example, we are analyzing a **fact (Sales)** & we have the folowing **dimensions:**<br/>* Premises for sale - sotre 1, store 2, & store 3<br/>* Sale value - 120, 185, 47, & so on<br/>* Product category - Pharmacy, Grocery, Produce, & Dairy<br/>* Sale months - June, July, Aug, Sept, & Oct|
|63|Data ingestion type|<ins>Batch processing</ins><br/><br/><ins>Stream processing</ins>|
|64|Azure Synapse Pipelines||<img src="https://i.imgur.com/hgCCtIG.png">|
|65|Data warehouse|
|66|Data Lake|<ins>Spark</ins><br/><br/><ins>Hadoop</ins>
|67|Delta Lake|
|68|Elastic pool|An Azure SQL Database elastic pool is a **service** where you can have **multiple databases, sharing the same resources** sunch as **memory,data storage space, & computing power**<br/><br/> Pool is a term used to describe a collection of resources, in this context, a collection of databases that share the same Azure SQL Database cluster|
|69|pgAdmin|
